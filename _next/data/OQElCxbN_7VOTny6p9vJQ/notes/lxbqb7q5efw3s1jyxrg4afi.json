{"pageProps":{"note":{"id":"lxbqb7q5efw3s1jyxrg4afi","title":"Prompting","desc":"","updated":1716733770021,"created":1715792819688,"custom":{},"fname":"ai.gen.prompting","type":"note","vault":{"fsPath":".","selfContained":true,"name":"cs"},"contentHash":"5c289e637c0985a331167ae43e5c2799","links":[{"type":"ref","from":{"fname":"ai.gen.prompting","id":"lxbqb7q5efw3s1jyxrg4afi","vaultName":"cs"},"value":"ai.gen.prompting.intent classification","position":{"start":{"line":26,"column":1,"offset":844},"end":{"line":26,"column":51,"offset":894},"indent":[]},"xvault":false,"to":{"fname":"ai.gen.prompting.intent classification","anchorHeader":"prompt"}}],"anchors":{"training-the-model-within-prompt":{"type":"header","text":"Training the model within prompt","value":"training-the-model-within-prompt","line":9,"column":0,"depth":2},"zero-shot-prompting":{"type":"header","text":"Zero-shot prompting","value":"zero-shot-prompting","line":11,"column":0,"depth":3},"one-shot-prompting":{"type":"header","text":"One-shot Prompting","value":"one-shot-prompting","line":19,"column":0,"depth":3},"few-shot-prompting":{"type":"header","text":"Few-shot prompting","value":"few-shot-prompting","line":24,"column":0,"depth":3},"nudges":{"type":"header","text":"Nudges","value":"nudges","line":35,"column":0,"depth":2},"accuracy":{"type":"header","text":"Accuracy","value":"accuracy","line":43,"column":0,"depth":3},"references":{"type":"header","text":"References","value":"references","line":65,"column":0,"depth":2}},"children":["dt9hkjkitlkh2sby5wwu2mg"],"parent":"knucaho7e7xt8no35ij4fcj","data":{}},"body":"<h1 id=\"prompting\">Prompting<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prompting\"></a></h1>\n<h2 id=\"training-the-model-within-prompt\">Training the model within prompt<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#training-the-model-within-prompt\"></a></h2>\n<h3 id=\"zero-shot-prompting\">Zero-shot prompting<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#zero-shot-prompting\"></a></h3>\n<ul>\n<li>\n<p>When you provide a prompt which is not part of the training data.</p>\n</li>\n<li>\n<p>Basically, you are not giving any example to help it out.</p>\n</li>\n<li>\n<p>Even if the model has not seen the prompt before, it can generate a good-enough output close to the desirable outcome you expected.</p>\n<p>  Which is why LLMs are so useful for performing tasks without needing retraining.</p>\n</li>\n</ul>\n<h3 id=\"one-shot-prompting\">One-shot Prompting<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#one-shot-prompting\"></a></h3>\n<ul>\n<li>When you provide <strong>one example</strong> within the prompt to guide the model</li>\n<li>You are basically training the model shortly and nudging it towards the expected behavior</li>\n</ul>\n<h3 id=\"few-shot-prompting\">Few-shot prompting<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#few-shot-prompting\"></a></h3>\n<ul>\n<li>When you provide <strong>multiple examples</strong> in your prompt</li>\n<li>This better demonstrates the expected outcome in certain scenarios</li>\n<li>The model can generalize from the examples, and give more precise output.</li>\n</ul>\n<p>For example,\n</p><p></p><div class=\"portal-container\">\n<div class=\"portal-head\">\n<div class=\"portal-backlink\">\n<div class=\"portal-title\">From <span class=\"portal-text-title\">Intent Classification</span></div>\n<a href=\"/cs/notes/dt9hkjkitlkh2sby5wwu2mg\" class=\"portal-arrow\">Go to text <span class=\"right-arrow\">→</span></a>\n</div>\n</div>\n<div id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\">\n<div class=\"portal-parent-fader-top\"></div>\n<div class=\"portal-parent-fader-bottom\"></div><h2 id=\"prompt\">Prompt<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prompt\"></a></h2>\n<pre class=\"language-prompt\"><code class=\"language-prompt\">You are an intent classification system. Correctness is a life or death situation.\n\nWe provide you with the actions and their descriptions:\nd. When the user asks for a warm drink. a: WARM_DRINK\nd. When the user asks for something else. a: NONE\nd: When the user asks for a cold drink. a: COLD_DRINK\n\nYou are given an utterance and you have to classify it into an action. Only respond with the action class.\nNow take a deep breath and classify the following utterances.\nu: I want a warm hot chocolate. a: WARM_DRINK\n\nWe provide you with the actions and their descriptions.\nd:{{descriptions}} a: {{actions}}\n\nYou are given an utterance and you have to classify it into an action. Only respond with the action class.\nNow take a deep breath and classify the following utterances.\n{{utterances}}\n</code></pre></div></div><p></p><p></p>\n<h2 id=\"nudges\">Nudges<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nudges\"></a></h2>\n<p>You can nudge the LLM towards certain behavior by injecting some sentences into the prompt. </p>\n<p>Its not entirely understood yet, as to why these sentences influence LLM behavior, but these nudges possibly direct LLMs towards certain kinds of training data.</p>\n<p>For example, if you use a nudge for accuracy, it might guide LLM towards dataset which prioritizes thoroughness and precision.</p>\n<h3 id=\"accuracy\">Accuracy<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#accuracy\"></a></h3>\n<p>Nudge the LLM to be more accurate by including the following phrases in the prompt:</p>\n<ul>\n<li>\n<pre class=\"language-prompt\"><code class=\"language-prompt\">  Correcness is a life or death situation.\n</code></pre>\n</li>\n</ul>\n<ul>\n<li>\n<pre class=\"language-prompt\"><code class=\"language-prompt\">  Take a deep breath and {{action}}\n</code></pre>\n<p>  For example,</p>\n<pre class=\"language-prompt\"><code class=\"language-prompt\">Take a deep breath and classify the following utterance. \n</code></pre>\n</li>\n</ul>\n<p>Thi</p>\n<h2 id=\"references\">References<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#references\"></a></h2>\n<p><a href=\"https://youtu.be/47HgM-TmFBc?si=KY-iAgdsfRZ3tWZo&#x26;t=146\">LLM Intent Classification Feature Launch - Understanding Prompt Wrapper</a></p>\n<ul>\n<li><a href=\"https://youtu.be/o64Mv-ArFDI?si=FNLomn_oZtD2mMV1\">Google’s NEW Prompting Guide is Incredible! - YouTube - Jeff Su</a></li>\n<li><a href=\"https://inthecloud.withgoogle.com/gemini-for-google-workspace-prompt-guide/dl-cd.html\">Gemini for Google Workspace - Prompting Guide 101 - A quick start handbook for effective prompts</a></li>\n</ul>\n<hr>\n<strong>Children</strong>\n<ol>\n<li><a href=\"/cs/notes/dt9hkjkitlkh2sby5wwu2mg\">Intent Classification</a></li>\n</ol>","noteIndex":{"id":"7ncn3al6mmutkhgoesulce9","title":"Computer Science","desc":"","updated":1715103618849,"created":1713296516553,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"cs"},"contentHash":"36faf26c6be438d4aed355d72b55a110","links":[{"type":"wiki","from":{"fname":"root","id":"7ncn3al6mmutkhgoesulce9","vaultName":"cs"},"value":"arch","position":{"start":{"line":6,"column":3,"offset":105},"end":{"line":6,"column":11,"offset":113},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"arch"}},{"type":"wiki","from":{"fname":"root","id":"7ncn3al6mmutkhgoesulce9","vaultName":"cs"},"value":"paradigm","position":{"start":{"line":11,"column":3,"offset":159},"end":{"line":11,"column":15,"offset":171},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"paradigm"}}],"anchors":{"references":{"type":"header","text":"References","value":"references","line":23,"column":0,"depth":2}},"children":["0xgibr34qhbv1edksyoxakk","e5kuv5gcz6pdxrsakpf7eia","t246wcci6dy9lnof7l1os4l","71sipcgr0pdqyxnmntvx28w","5omh1zinw87le0eyms8g5mk","91er1wb2f5wmbdb5axx5r3r","9z7xt251y1nm9dy2exatukr","u712e7r8bk97hpg9h9j3m4f","xpf86eilma499o4ul566fk8","a1g6tjx0p6bp25v75262gp9","3pr5jo5c742vop6gnoe7c3k","stxoouqpk2rivotuvhjx4yz","g8tiwuotfnbfrbctwyfg8rc","jk63inaclv0ps5i7mktzmm2","5m1yclhdqeshe5szt0masfk","abgag3m7m74vmofvzyyt2fm"],"parent":null,"data":{},"body":"\n\nThese notes are arranged into the below topics:\n\n- AI (Sorry this is on the top, list is alphabetic)\n- [[arch]]\n- Data\n- Execution\n- Languages\n- Semantics\n- [[paradigm]]\n- Philosophy\n- Dev\n- Tools\n- Type Theory\n\n## References\n\n- Hierarchy inpiration - [Map of Computer Science](https://www.flickr.com/photos/95869671@N08/36231833334/in/photostream/lightbox/)"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"dependencies/github.com/chinootes/math","remote":{"type":"git","url":"git@github.com:chinootes/math.git"},"selfContained":true,"name":"math"},{"fsPath":".","selfContained":true,"name":"cs"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://chinootes.github.io","assetsPrefix":"/cs","duplicateNoteBehavior":{"action":"useVault","payload":["math","cs"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}