<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/cs/favicon.ico"/><title>Prompting</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="Prompting"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://chinootes.github.io/cs/notes/lxbqb7q5efw3s1jyxrg4afi/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="5/15/2024"/><meta property="article:modified_time" content="5/26/2024"/><link rel="canonical" href="https://chinootes.github.io/cs/notes/lxbqb7q5efw3s1jyxrg4afi/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/cs/_next/static/css/896e35ac335ee88a.css" as="style"/><link rel="stylesheet" href="/cs/_next/static/css/896e35ac335ee88a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/cs/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/cs/_next/static/chunks/webpack-114d62680617a3fa.js" defer=""></script><script src="/cs/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/cs/_next/static/chunks/main-909e1e4186772aeb.js" defer=""></script><script src="/cs/_next/static/chunks/pages/_app-13bb43f56c9a0d26.js" defer=""></script><script src="/cs/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/cs/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/cs/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/cs/_next/static/OQElCxbN_7VOTny6p9vJQ/_buildManifest.js" defer=""></script><script src="/cs/_next/static/OQElCxbN_7VOTny6p9vJQ/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="prompting">Prompting<a aria-hidden="true" class="anchor-heading icon-link" href="#prompting"></a></h1>
<h2 id="training-the-model-within-prompt">Training the model within prompt<a aria-hidden="true" class="anchor-heading icon-link" href="#training-the-model-within-prompt"></a></h2>
<h3 id="zero-shot-prompting">Zero-shot prompting<a aria-hidden="true" class="anchor-heading icon-link" href="#zero-shot-prompting"></a></h3>
<ul>
<li>
<p>When you provide a prompt which is not part of the training data.</p>
</li>
<li>
<p>Basically, you are not giving any example to help it out.</p>
</li>
<li>
<p>Even if the model has not seen the prompt before, it can generate a good-enough output close to the desirable outcome you expected.</p>
<p>  Which is why LLMs are so useful for performing tasks without needing retraining.</p>
</li>
</ul>
<h3 id="one-shot-prompting">One-shot Prompting<a aria-hidden="true" class="anchor-heading icon-link" href="#one-shot-prompting"></a></h3>
<ul>
<li>When you provide <strong>one example</strong> within the prompt to guide the model</li>
<li>You are basically training the model shortly and nudging it towards the expected behavior</li>
</ul>
<h3 id="few-shot-prompting">Few-shot prompting<a aria-hidden="true" class="anchor-heading icon-link" href="#few-shot-prompting"></a></h3>
<ul>
<li>When you provide <strong>multiple examples</strong> in your prompt</li>
<li>This better demonstrates the expected outcome in certain scenarios</li>
<li>The model can generalize from the examples, and give more precise output.</li>
</ul>
<p>For example,
</p><p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">Intent Classification</span></div>
<a href="/cs/notes/dt9hkjkitlkh2sby5wwu2mg" class="portal-arrow">Go to text <span class="right-arrow">→</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><h2 id="prompt">Prompt<a aria-hidden="true" class="anchor-heading icon-link" href="#prompt"></a></h2>
<pre class="language-prompt"><code class="language-prompt">You are an intent classification system. Correctness is a life or death situation.

We provide you with the actions and their descriptions:
d. When the user asks for a warm drink. a: WARM_DRINK
d. When the user asks for something else. a: NONE
d: When the user asks for a cold drink. a: COLD_DRINK

You are given an utterance and you have to classify it into an action. Only respond with the action class.
Now take a deep breath and classify the following utterances.
u: I want a warm hot chocolate. a: WARM_DRINK

We provide you with the actions and their descriptions.
d:{{descriptions}} a: {{actions}}

You are given an utterance and you have to classify it into an action. Only respond with the action class.
Now take a deep breath and classify the following utterances.
{{utterances}}
</code></pre></div></div><p></p><p></p>
<h2 id="nudges">Nudges<a aria-hidden="true" class="anchor-heading icon-link" href="#nudges"></a></h2>
<p>You can nudge the LLM towards certain behavior by injecting some sentences into the prompt. </p>
<p>Its not entirely understood yet, as to why these sentences influence LLM behavior, but these nudges possibly direct LLMs towards certain kinds of training data.</p>
<p>For example, if you use a nudge for accuracy, it might guide LLM towards dataset which prioritizes thoroughness and precision.</p>
<h3 id="accuracy">Accuracy<a aria-hidden="true" class="anchor-heading icon-link" href="#accuracy"></a></h3>
<p>Nudge the LLM to be more accurate by including the following phrases in the prompt:</p>
<ul>
<li>
<pre class="language-prompt"><code class="language-prompt">  Correcness is a life or death situation.
</code></pre>
</li>
</ul>
<ul>
<li>
<pre class="language-prompt"><code class="language-prompt">  Take a deep breath and {{action}}
</code></pre>
<p>  For example,</p>
<pre class="language-prompt"><code class="language-prompt">Take a deep breath and classify the following utterance. 
</code></pre>
</li>
</ul>
<p>Thi</p>
<h2 id="references">References<a aria-hidden="true" class="anchor-heading icon-link" href="#references"></a></h2>
<p><a href="https://youtu.be/47HgM-TmFBc?si=KY-iAgdsfRZ3tWZo&#x26;t=146">LLM Intent Classification Feature Launch - Understanding Prompt Wrapper</a></p>
<ul>
<li><a href="https://youtu.be/o64Mv-ArFDI?si=FNLomn_oZtD2mMV1">Google’s NEW Prompting Guide is Incredible! - YouTube - Jeff Su</a></li>
<li><a href="https://inthecloud.withgoogle.com/gemini-for-google-workspace-prompt-guide/dl-cd.html">Gemini for Google Workspace - Prompting Guide 101 - A quick start handbook for effective prompts</a></li>
</ul>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/cs/notes/dt9hkjkitlkh2sby5wwu2mg">Intent Classification</a></li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#training-the-model-within-prompt" title="Training the model within prompt">Training the model within prompt</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#zero-shot-prompting" title="Zero-shot prompting">Zero-shot prompting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#one-shot-prompting" title="One-shot Prompting">One-shot Prompting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#few-shot-prompting" title="Few-shot prompting">Few-shot prompting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#nudges" title="Nudges">Nudges</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#accuracy" title="Accuracy">Accuracy</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#references" title="References">References</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"lxbqb7q5efw3s1jyxrg4afi","title":"Prompting","desc":"","updated":1716733770021,"created":1715792819688,"custom":{},"fname":"ai.gen.prompting","type":"note","vault":{"fsPath":".","selfContained":true,"name":"cs"},"contentHash":"5c289e637c0985a331167ae43e5c2799","links":[{"type":"ref","from":{"fname":"ai.gen.prompting","id":"lxbqb7q5efw3s1jyxrg4afi","vaultName":"cs"},"value":"ai.gen.prompting.intent classification","position":{"start":{"line":26,"column":1,"offset":844},"end":{"line":26,"column":51,"offset":894},"indent":[]},"xvault":false,"to":{"fname":"ai.gen.prompting.intent classification","anchorHeader":"prompt"}}],"anchors":{"training-the-model-within-prompt":{"type":"header","text":"Training the model within prompt","value":"training-the-model-within-prompt","line":9,"column":0,"depth":2},"zero-shot-prompting":{"type":"header","text":"Zero-shot prompting","value":"zero-shot-prompting","line":11,"column":0,"depth":3},"one-shot-prompting":{"type":"header","text":"One-shot Prompting","value":"one-shot-prompting","line":19,"column":0,"depth":3},"few-shot-prompting":{"type":"header","text":"Few-shot prompting","value":"few-shot-prompting","line":24,"column":0,"depth":3},"nudges":{"type":"header","text":"Nudges","value":"nudges","line":35,"column":0,"depth":2},"accuracy":{"type":"header","text":"Accuracy","value":"accuracy","line":43,"column":0,"depth":3},"references":{"type":"header","text":"References","value":"references","line":65,"column":0,"depth":2}},"children":["dt9hkjkitlkh2sby5wwu2mg"],"parent":"knucaho7e7xt8no35ij4fcj","data":{}},"body":"\u003ch1 id=\"prompting\"\u003ePrompting\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prompting\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch2 id=\"training-the-model-within-prompt\"\u003eTraining the model within prompt\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#training-the-model-within-prompt\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"zero-shot-prompting\"\u003eZero-shot prompting\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#zero-shot-prompting\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eWhen you provide a prompt which is not part of the training data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBasically, you are not giving any example to help it out.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eEven if the model has not seen the prompt before, it can generate a good-enough output close to the desirable outcome you expected.\u003c/p\u003e\n\u003cp\u003e  Which is why LLMs are so useful for performing tasks without needing retraining.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"one-shot-prompting\"\u003eOne-shot Prompting\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#one-shot-prompting\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you provide \u003cstrong\u003eone example\u003c/strong\u003e within the prompt to guide the model\u003c/li\u003e\n\u003cli\u003eYou are basically training the model shortly and nudging it towards the expected behavior\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"few-shot-prompting\"\u003eFew-shot prompting\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#few-shot-prompting\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eWhen you provide \u003cstrong\u003emultiple examples\u003c/strong\u003e in your prompt\u003c/li\u003e\n\u003cli\u003eThis better demonstrates the expected outcome in certain scenarios\u003c/li\u003e\n\u003cli\u003eThe model can generalize from the examples, and give more precise output.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor example,\n\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"portal-container\"\u003e\n\u003cdiv class=\"portal-head\"\u003e\n\u003cdiv class=\"portal-backlink\"\u003e\n\u003cdiv class=\"portal-title\"\u003eFrom \u003cspan class=\"portal-text-title\"\u003eIntent Classification\u003c/span\u003e\u003c/div\u003e\n\u003ca href=\"/cs/notes/dt9hkjkitlkh2sby5wwu2mg\" class=\"portal-arrow\"\u003eGo to text \u003cspan class=\"right-arrow\"\u003e→\u003c/span\u003e\u003c/a\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\"\u003e\n\u003cdiv class=\"portal-parent-fader-top\"\u003e\u003c/div\u003e\n\u003cdiv class=\"portal-parent-fader-bottom\"\u003e\u003c/div\u003e\u003ch2 id=\"prompt\"\u003ePrompt\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prompt\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cpre class=\"language-prompt\"\u003e\u003ccode class=\"language-prompt\"\u003eYou are an intent classification system. Correctness is a life or death situation.\n\nWe provide you with the actions and their descriptions:\nd. When the user asks for a warm drink. a: WARM_DRINK\nd. When the user asks for something else. a: NONE\nd: When the user asks for a cold drink. a: COLD_DRINK\n\nYou are given an utterance and you have to classify it into an action. Only respond with the action class.\nNow take a deep breath and classify the following utterances.\nu: I want a warm hot chocolate. a: WARM_DRINK\n\nWe provide you with the actions and their descriptions.\nd:{{descriptions}} a: {{actions}}\n\nYou are given an utterance and you have to classify it into an action. Only respond with the action class.\nNow take a deep breath and classify the following utterances.\n{{utterances}}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\u003ch2 id=\"nudges\"\u003eNudges\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nudges\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eYou can nudge the LLM towards certain behavior by injecting some sentences into the prompt. \u003c/p\u003e\n\u003cp\u003eIts not entirely understood yet, as to why these sentences influence LLM behavior, but these nudges possibly direct LLMs towards certain kinds of training data.\u003c/p\u003e\n\u003cp\u003eFor example, if you use a nudge for accuracy, it might guide LLM towards dataset which prioritizes thoroughness and precision.\u003c/p\u003e\n\u003ch3 id=\"accuracy\"\u003eAccuracy\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#accuracy\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eNudge the LLM to be more accurate by including the following phrases in the prompt:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cpre class=\"language-prompt\"\u003e\u003ccode class=\"language-prompt\"\u003e  Correcness is a life or death situation.\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cpre class=\"language-prompt\"\u003e\u003ccode class=\"language-prompt\"\u003e  Take a deep breath and {{action}}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e  For example,\u003c/p\u003e\n\u003cpre class=\"language-prompt\"\u003e\u003ccode class=\"language-prompt\"\u003eTake a deep breath and classify the following utterance. \n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThi\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#references\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://youtu.be/47HgM-TmFBc?si=KY-iAgdsfRZ3tWZo\u0026#x26;t=146\"\u003eLLM Intent Classification Feature Launch - Understanding Prompt Wrapper\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://youtu.be/o64Mv-ArFDI?si=FNLomn_oZtD2mMV1\"\u003eGoogle’s NEW Prompting Guide is Incredible! - YouTube - Jeff Su\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://inthecloud.withgoogle.com/gemini-for-google-workspace-prompt-guide/dl-cd.html\"\u003eGemini for Google Workspace - Prompting Guide 101 - A quick start handbook for effective prompts\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cstrong\u003eChildren\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/cs/notes/dt9hkjkitlkh2sby5wwu2mg\"\u003eIntent Classification\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e","noteIndex":{"id":"7ncn3al6mmutkhgoesulce9","title":"Computer Science","desc":"","updated":1715103618849,"created":1713296516553,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"cs"},"contentHash":"36faf26c6be438d4aed355d72b55a110","links":[{"type":"wiki","from":{"fname":"root","id":"7ncn3al6mmutkhgoesulce9","vaultName":"cs"},"value":"arch","position":{"start":{"line":6,"column":3,"offset":105},"end":{"line":6,"column":11,"offset":113},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"arch"}},{"type":"wiki","from":{"fname":"root","id":"7ncn3al6mmutkhgoesulce9","vaultName":"cs"},"value":"paradigm","position":{"start":{"line":11,"column":3,"offset":159},"end":{"line":11,"column":15,"offset":171},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"paradigm"}}],"anchors":{"references":{"type":"header","text":"References","value":"references","line":23,"column":0,"depth":2}},"children":["0xgibr34qhbv1edksyoxakk","e5kuv5gcz6pdxrsakpf7eia","t246wcci6dy9lnof7l1os4l","71sipcgr0pdqyxnmntvx28w","5omh1zinw87le0eyms8g5mk","91er1wb2f5wmbdb5axx5r3r","9z7xt251y1nm9dy2exatukr","u712e7r8bk97hpg9h9j3m4f","xpf86eilma499o4ul566fk8","a1g6tjx0p6bp25v75262gp9","3pr5jo5c742vop6gnoe7c3k","stxoouqpk2rivotuvhjx4yz","g8tiwuotfnbfrbctwyfg8rc","jk63inaclv0ps5i7mktzmm2","5m1yclhdqeshe5szt0masfk","abgag3m7m74vmofvzyyt2fm"],"parent":null,"data":{},"body":"\n\nThese notes are arranged into the below topics:\n\n- AI (Sorry this is on the top, list is alphabetic)\n- [[arch]]\n- Data\n- Execution\n- Languages\n- Semantics\n- [[paradigm]]\n- Philosophy\n- Dev\n- Tools\n- Type Theory\n\n## References\n\n- Hierarchy inpiration - [Map of Computer Science](https://www.flickr.com/photos/95869671@N08/36231833334/in/photostream/lightbox/)"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"dependencies/github.com/chinootes/math","remote":{"type":"git","url":"git@github.com:chinootes/math.git"},"selfContained":true,"name":"math"},{"fsPath":".","selfContained":true,"name":"cs"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://chinootes.github.io","assetsPrefix":"/cs","duplicateNoteBehavior":{"action":"useVault","payload":["math","cs"]},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"lxbqb7q5efw3s1jyxrg4afi"},"buildId":"OQElCxbN_7VOTny6p9vJQ","assetPrefix":"/cs","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>